---
title: "Preferencias de hábitat de las lagartijas"
format: html
editor_options: 
  chunk_output_type: console
---

```{r}
library(detectseparation) # datos lizards
```

## Descripción del conjunto de datos

Se recopilaron datos sobre los hábitos diurnos de dos especies de lagartijas: *grahami* y *opalinus*. Las observaciones se realizaron registrando las características del sitio ocupado o percha. Para cada observación se anotaron:

- **Especie** observada (*grahami* u *opalinus*)
- **Momento del día**: temprano, medio día o tarde
- **Altura** de la percha
- **Diámetro** de la percha
- **Condición de luz** del sitio: soleado o sombreado

```{r}
data("lizards")
lizards
```

Se desea comparar dos especies de lagartijas (*grahami* y *opalinus*) con respecto a sus preferencias por sitios de percha. Se asume que:

- La probabilidad de detectar un sitio ocupado es la misma para ambas especies.
- El objetivo es comparar a las dos especies de lagartijas (*grahami* y *opalinus*) en cuanto a su ocupación de diferentes tipos de perchas, caracterizadas por altura, diámetro, luz (sol/sombra) y momento del día.

- Para cada combinación de estas variables, se fija el número total de sitios ocupados observados (`m_{ijkl}`).
  - `i`: **Altura** de la percha  
  - `j`: **Diámetro** de la percha  
  - `k`: **Condición de luz** (soleado o sombreado)  
  - `l`: **Momento del día** (temprano, medio día o tarde)
- La variable respuesta `Y_{ijkl}` es el número (o proporción) de sitios ocupados por *grahami* entre los `m_{ijkl}` observados. Se modela como una binomial con índice `m_{ijkl}` y probabilidad `π_{ijkl}` de que un sitio ocupado lo sea por *grahami*.

Por ejemplo:
- De 22 perchas observadas **temprano en el día**, con **diámetro pequeño**, **bajas** y en **sol**, solo 2 (9%) estaban ocupadas por *opalinus* (es decir, 20 por *grahami*).
- En condiciones similares pero observadas **más tarde en el día**, *opalinus* ocupó 4 de 8 (50%).

Esto sugiere que *grahami* prefiere exponerse al sol temprano en el día, en comparación con *opalinus*.

El análisis se formaliza con un modelo **binomial** para `Y_{ijkl}` con índice `m_{ijkl}` y proporción `π_{ijkl}`.

```{r}
# transformaciones logísticas
# lizards$m <- lizards$grahami + lizards$opalinus
# lizards$Y <- lizards$grahami
# 
# lizards$Z <- log((lizards$Y + 0.5) / (lizards$m - lizards$Y + 0.5))
# 
# lizards$var_Z <- 1 / (lizards$Y + 0.5) + 1 / (lizards$m - lizards$Y + 0.5)
# lizards$weights <- 1 / lizards$var_Z
```

```{r}
# conviertiendo a factores
lizards$height   <- factor(lizards$height, levels = c("<5ft", ">=5ft"))
lizards$diameter <- factor(lizards$diameter, levels = c("<=2in", ">2in"))
lizards$light    <- factor(lizards$light, levels = c("sunny", "shady"))
lizards$time     <- factor(lizards$time, levels = c("early", "midday", "late"))
```

Antes de comenzar un pequeño análisis descriptivo de los datos:
```{r}
library(GGally)
library(ggplot2)
library(dplyr)
lizards[,c(1,2)] %>% ggpairs(
    upper = list(continuous = wrap("cor", size = 2)),
    diag = list(continuous = wrap("barDiag", colour = "burlywood")),
    lower = list(continuous = wrap("points", alpha = 0.5, shape = 20, 
                                   fill = "lightblue")),
    axisLabels = "none") + 
  theme(strip.text = element_text(size = 6))
```
Se ve claramente una alta correlación lineal, teniendo en cuenta que la correlación utilizada en este caso fue la correlación de Pearson. Ambas variables tienden a tener mas valores bajos que altos aunque no se sabe si mutuamente.

```{r}
for (i in c(1,2)) {
  y_col_name <- names(lizards)[i]

  for (j in c(3,4,5,6)) {
    x_col_name <- names(lizards)[j]
     p <- ggplot(lizards,
            aes(x = !!sym(x_col_name),
                y = !!sym(y_col_name), 
                colour = !!sym(x_col_name))) +
        geom_boxplot() +
    labs(
    title = paste("Boxplot de", y_col_name, "por", x_col_name),
    x = x_col_name,
    y = paste("Número de", y_col_name)
    ) +
    theme_minimal()
     print(p)
  }
}
```
De los gráficos podemos notar que hay gráficos en lso que no parece haber diferencia de grupos como lo son los graficos de "grahami por height" y "opalinus por diameter", ambos muestran en ambos grupos datos atípicos y la diferencia de dispersión es poca o casi nula, respectivamente.

Se observa que ambas especies presentan diferencia de grupos por "luz" donde se ve más dispersión una mediana más alta en "sombra" que en "soleado", aunque para "grahami se presenta un dato atípico en "soleado" a diferencia de opalinus que es más consistente en soleado. Por otro lado "opalinus" prenta un dato atípico en "sombra" a difrencia de "grahami".

Por último se destaca que para ambas especies se ve el mismo orden de comportamiento de dispersión de los grupos dados por hora del día, el cual es en primer lugar con mayor dispersión "midday" le sigue "early" y por último "late". Aunque se ve más dispersión en "grahami" en "midday", no presenta datos atípicos, totalmente opuesto a "opalinos quien maneja menor dispersión sin imbargo presentó un dato atípico.

En general "opalinus" tiene resultados un poco más consistentes (menor dispersión) y con valores que tienden a ser menores a comparación con "grahami".

```{r}
boxplot(lizards$grahami,
        main="grahami",
        ylab="Número de grahami")
boxplot(lizards$opalinus,
        main="opalinus",
        ylab="Número de opalinus")

```

Se ajusta un modelom lineal generalizado incluyendo los efectos principales: $H + D + S + T$. El modelo está dado por:

$$p\left(\frac{\pi_{ijkl}}{1 - \pi_{ijkl}}\right) = \mu + \alpha_i + \beta_j + \gamma_k + \delta_l$$

```{r}
# matriz de éxitos y fracasos
response <- cbind(success = lizards$grahami, failure = lizards$opalinus)

# modelo MLG logístico
fit_main <- glm(response ~ height + diameter + light + time,
                family = binomial, data = lizards)

# Summary of the model
summary(fit_main)
```

Todos los efectos principales son estadísticamente significativos al $5\%$.

Ninguna de las interacciones es significativa. Las diferencias en la devianza de cada modelo con interacción respecto al modelo de efectos principales no es significativa. Se concluye que el modelo con efectos principales ajusta bien los datos.

```{r}
# Modelos con interacciones (una por una)

fit_TS <- glm(response ~ height + diameter + light + time + time:light, family = binomial, data = lizards)

fit_TH <- glm(response ~ height + diameter + light + time + time:height, family = binomial, data = lizards)

fit_TD <- glm(response ~ height + diameter + light + time + time:diameter, family = binomial, data = lizards)

fit_SH <- glm(response ~ height + diameter + light + time + light:height, family = binomial, data = lizards)

fit_SD <- glm(response ~ height + diameter + light + time + light:diameter, family = binomial, data = lizards)

fit_HD <- glm(response ~ height + diameter + light + time + height:diameter, family = binomial, data = lizards)

models <- list(fit_main, fit_TS, fit_TH, fit_TD, fit_SH, fit_SD, fit_HD)
labels <- c("Main", "T.S", "T.H", "T.D", "S.H", "S.D", "H.D")

# grados de libertad y devianzas
dfs <- sapply(models, df.residual)
deviances <- sapply(models, deviance)

# diferencias en la devianza
diffs <- c(NA, round(deviances[1] - deviances[-1], 2))

# tabla
tab47 <- data.frame(
  Model = labels,
  Df = dfs,
  Deviance = round(deviances, 2),
  `First difference` = diffs
)

print(tab47, row.names = FALSE)
```

```{r}
# residuales de pearson estandarizados vs valores predichos

resid_std <- rstandard(fit_main, type = "pearson")

lizards$resid_std <- resid_std
lizards$fitted    <- fitted(fit_main)

plot(lizards$fitted, lizards$resid_std,
     xlab = "Fitted values", ylab = "Standardized residuals",
     main = "Residuals vs Fitted")
abline(h = 0, col = "gray")
```

```{r}
# Verificar sobredispersión (residuos Pearson al cuadrado)
dispersion <- sum(residuals(fit_main, type = "pearson")^2) / df.residual(fit_main)
dispersion
```
```{r}
qqnorm(residuals(fit_main, type = "pearson"))
qqline(residuals(fit_main, type = "pearson"))
```
Se ve que los puntos tienden a estar alrededor de la recta por lo que se ve que los residuales tienen un comportamiento normal, además de esto se realizó una prueba de normalidad
```{r}
shapiro.test(residuals(fit_main, type = "pearson"))
```
El p valor de la prueba fue mayor al nivel de significancia, el cual es 0.05, por lo que no se rechaza la hipótesis de normalidad.

